{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INT IDS Long-slit Spectroscopy Reduction\n",
    "\n",
    "This pipeline performs all the basic CCD data reduction. The steps are as follows:\n",
    "- create a master bias frame\n",
    "- create a master lamp flat frame\n",
    "- create a master sky flat frame\n",
    "\n",
    "- reduce individual science frames. Perform gain correction, bias subtraction, flat fielding and sky subtraction\n",
    "- median combine reduced science frames into a deep spectrum\n",
    "\n",
    "- reduce arc frames for wavelength calibration\n",
    "\n",
    "- wavelength calibrate the 2D science spectrum\n",
    "- extract and save 1D spectrum from a given position and aperture size. This feature requires the python package mpdaf. This can be downloaded using `pip install mpdaf` for python2 or `pip3 install mpdaf` for python3.\n",
    "\n",
    "To add: flux calibration\n",
    "\n",
    "The following reduction code works directly from the full set of images in a given night's observations. As observations are added during the evening, the ImageFileCollection object defined at the beginning needs to be refreshed.\n",
    "\n",
    "ftp where frames are stored: rsync -av intobs@intdrpc1:/obsdata/inta/20190405/ .\n",
    "\n",
    "password: int_guest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import all relevant packages.\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.modeling import models, fitting\n",
    "from astropy.stats import sigma_clip, mad_std\n",
    "from astropy.convolution import convolve, Gaussian2DKernel\n",
    "\n",
    "from scipy.ndimage import binary_dilation\n",
    "from astropy.utils.console import ProgressBar\n",
    "\n",
    "import ccdproc\n",
    "from ccdproc import ImageFileCollection, CCDData\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "import glob\n",
    "\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpdaf.obj import Spectrum, WaveCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define functions relevant for calibration\n",
    "\n",
    "def fit_chebyshev(row, degree=7, grow=3):\n",
    "    \"\"\"\n",
    "    Fit Chebyshev1D model to a CCD row, including masking of outlier pixels\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    row : array,\n",
    "        Input CCD row to fit polynomial to.\n",
    "    degree : int,\n",
    "        Chebyshev Polynomial Order\n",
    "    grow : int,\n",
    "        Number of iterations to dilate around masked pixels\n",
    "    \"\"\"\n",
    "\n",
    "    fitter = fitting.LinearLSQFitter()\n",
    "    input_mask = row.mask\n",
    "    clipped = sigma_clip(row, stdfunc=mad_std)\n",
    "    clipped_pixels = np.array(clipped.mask+row.mask).astype('float')\n",
    "    clipped_pixels = binary_dilation(clipped_pixels, iterations=grow)\n",
    "\n",
    "    row[clipped_pixels==1] = np.median(row)\n",
    "    masked_row = np.ma.array(data=row, \n",
    "                             mask=(clipped_pixels == 1), \n",
    "                             fill_value=np.median(row))\n",
    "    x = np.arange(len(row))\n",
    "    model = models.Chebyshev1D(degree=degree)\n",
    "    fitted_model = fitter(model, x, row)\n",
    "    return fitted_model(np.arange(len(row)))\n",
    "\n",
    "\n",
    "def fit_background(data, degree=7, grow=3, verbose=True, njobs=2):\n",
    "    \"\"\"\n",
    "    Parallelised background estimation for longslit CCD image\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    data : array,\n",
    "        Input CCD data for background estimation.\n",
    "    degree : int,\n",
    "        Chebyshev Polynomial Order\n",
    "    grow : int,\n",
    "        Number of iterations to dilate around masked pixels\n",
    "    njobs : int\n",
    "        Number of processes to initiate for fitting\n",
    "    \"\"\"\n",
    "    kwargs={'degree': degree, 'grow': grow}    \n",
    "    p = Pool(njobs)\n",
    "    fitted_sky = p.map(partial(fit_chebyshev, **kwargs), data)\n",
    "    p.close()\n",
    "    return np.array(fitted_sky).astype('float')\n",
    "\n",
    "\n",
    "### Edit the primary HDU and save\n",
    "\n",
    "def edit_header(filename):\n",
    "    hdulist = fits.open(filename)\n",
    "    hdr = hdulist[0].header\n",
    "    \n",
    "    try:\n",
    "        hdulist[0]\n",
    "        hdulist.writeto(filename, overwrite=True)\n",
    "    except KeyError:\n",
    "        print(\"Keyword not found!\")\n",
    "        \n",
    "        \n",
    "### Dispersion functions wavelength calibration\n",
    "def wavesol(x, m, c):\n",
    "    return m*x + c\n",
    "\n",
    "def gauss(x, *p):\n",
    "    A, mu, sigma = p\n",
    "    return A*np.exp(-(x-mu)**2/(2.*sigma**2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select observing night, the working directory and create the relevant folders\n",
    "\n",
    "obs_night = \"20190523\"\n",
    "\n",
    "### Directory with all the raw files from an observing night\n",
    "workdir = \"/Users/aayushsaxena/Desktop/phd/HzQ_2019/Data/INT_2019B/%s/\" %obs_night\n",
    "\n",
    "os.chdir(workdir)\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./processed_new/\")\n",
    "except OSError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load in all the files from the observing night\n",
    "\n",
    "### For non-standard keyword in the header, run the edit_header function below. \n",
    "### If no error is flagged by ic1 then this function is not required\n",
    "\n",
    "# filenames = glob.glob(\"*.fit\")\n",
    "# for file in filenames:\n",
    "#     edit_header(file)\n",
    "\n",
    "\n",
    "ic1 = ImageFileCollection(workdir)\n",
    "ic1.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ic1.files_filtered(obstype='TARGET', object=\"J160+54\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/read biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run this the first time to create master bias frames\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./processed_new/BIAS/\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "### Create red master bias\n",
    "red_bias_list = []\n",
    "\n",
    "for filename in ic1.files_filtered(obstype='BIAS', object='Bias'):\n",
    "    ccd = CCDData.read(ic1.location + filename, unit = u.electron)\n",
    "    ccd = ccdproc.subtract_overscan(ccd, median=True,  overscan_axis=0, overscan=ccd[4110:4190,:])\n",
    "    ccd = ccdproc.trim_image(ccd[:,:4096])\n",
    "\n",
    "    #this has to be fixed as the bias section does not include the whole section that will be trimmed\n",
    "    red_bias_list.append(ccd)\n",
    "\n",
    "master_bias = ccdproc.combine(red_bias_list, method='median')\n",
    "master_bias.write('./processed_new/BIAS/master_bias.fits', overwrite=True)\n",
    "\n",
    "### uncomment the following line once master bias created to simply load in the relevant bias\n",
    "# master_bias = CCDData.read('./processed/BIAS/master_bias.fits', unit=u.adu)\n",
    "\n",
    "print(\"Master Bias created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create/read flats\n",
    "\n",
    "### Lamp flats\n",
    "These are taken as part of the afternoon calibrations with complamps W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lamp flats\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"processed_new/FLAT/\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "red_flat_list = []\n",
    "for filename in ic1.files_filtered(obstype='FLAT'):\n",
    "    ccd = CCDData.read(ic1.location + filename, unit = u.electron)\n",
    "\n",
    "    #this has to be fixed as the bias section does not include the whole section that will be trimmed\n",
    "    ccd = ccdproc.subtract_overscan(ccd, median=True,  overscan_axis=0, overscan=ccd[4110:4190,:])\n",
    "    ccd = ccdproc.trim_image(ccd[:,:4096])\n",
    "    ccd = ccdproc.subtract_bias(ccd, master_bias)    \n",
    "    red_flat_list.append(ccd)\n",
    "\n",
    "master_flat = ccdproc.combine(red_flat_list, method='median')\n",
    "# convolved_flat = convolve(master_flat.data, kernel, boundary='extend')\n",
    "\n",
    "master_flat.write('./processed_new/FLAT/master_flat.fits', overwrite=True)\n",
    "\n",
    "### Uncomment the following line once master flats have been created\n",
    "# master_flat = CCDData.read('./processed/FLAT/master_flat.fits')\n",
    "\n",
    "print(\"Master flat created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sky flats\n",
    "These are taken around sunset (or sunrise). They have absorption lines but are superior to lamp flats as they give a more accurate flat-fielding for the science exposures. Give these priority. If for some reason sky flats were not taken, lamp flats should work too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sky flats\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"processed_new/FLAT/\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "skyflat_list = []\n",
    "for filename in ic1.files_filtered(obstype='SKY'):\n",
    "    ccd = CCDData.read(ic1.location + filename, unit = u.electron)\n",
    "#     ccd = ccdproc.create_deviation(ccd, gain=ccd.header['GAIN']*u.electron/u.adu, \n",
    "#                                    readnoise=ccd.header['READNOIS']*u.electron)\n",
    "    #this has to be fixed as the bias section does not include the whole section that will be trimmed\n",
    "    ccd = ccdproc.subtract_overscan(ccd, median=True,  overscan_axis=0, overscan=ccd[4110:4190,:])\n",
    "    ccd = ccdproc.trim_image(ccd[:,:4096])\n",
    "    ccd = ccdproc.subtract_bias(ccd, master_bias)    \n",
    "    skyflat_list.append(ccd)\n",
    "\n",
    "master_skyflat = ccdproc.combine(skyflat_list, method='median')\n",
    "# convolved_skyflat = convolve(master_skyflat.data, kernel, boundary='extend')\n",
    "\n",
    "master_skyflat.write('./processed_new/FLAT/master_skyflat.fits', overwrite=True)\n",
    "\n",
    "### Uncomment the following line once master flats have been created\n",
    "# master_skyflat = CCDData.read('./processed/FLAT/master_skyflat.fits')\n",
    "\n",
    "print(\"Master sky flat created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce science data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "objects = [\"J160+54\"] # Enter object name(s) (see from observing log)\n",
    "# files = [\"r1452844_trimmed.fit\"] # Enter object name(s) (see from observing log)\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./processed_new/SCI/\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "### Ignore masked array warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "### Refresh the file list to include new exposures\n",
    "# ic1 = ImageFileCollection(workdir)\n",
    "    \n",
    "### Reduce science frame\n",
    "for objname in objects:\n",
    "    print(\"Reducing:\", objname)\n",
    "    target_list = []\n",
    "    \n",
    "    for ifx, filename in enumerate(ic1.files_filtered(obstype='TARGET', file=objname)):\n",
    "        print('{0}'.format(filename))\n",
    "        hdu = fits.open(ic1.location + filename)\n",
    "        ccd = CCDData(hdu[1].data, header=hdu[0].header+hdu[1].header, unit = u.adu)\n",
    "        #this has to be fixed as the bias section does not include the whole section that will be trimmed\n",
    "        \n",
    "        ### gain correction\n",
    "        ccd = ccdproc.create_deviation(ccd, gain=ccd.header['GAIN']*u.electron/u.adu, \n",
    "                                       readnoise=ccd.header['READNOIS']*u.electron)\n",
    "        ccd = ccdproc.gain_correct(ccd, ccd.header['GAIN']*u.electron/u.adu)\n",
    "        ### Remove cosmic rays\n",
    "        ccd = ccdproc.cosmicray_lacosmic(ccd, sigclip=4., niter=10, sigfrac=0.3, psffwhm=2.5)\n",
    "        ### Subtract overscan\n",
    "        ccd = ccdproc.subtract_overscan(ccd, median=True,  overscan_axis=0, overscan=ccd[4110:4190,:])\n",
    "        ### Trim image\n",
    "        ccd = ccdproc.trim_image(ccd[:,:4096])\n",
    "        ### Subtract bias\n",
    "        ccd = ccdproc.subtract_bias(ccd, master_bias)\n",
    "        ### Flat correction\n",
    "        ccd = ccdproc.flat_correct(ccd, master_flat)\n",
    "\n",
    "\n",
    "        # Do sky subtraction\n",
    "        ccd.mask[:,79:89] = True\n",
    "        sky = fit_background(np.ma.array(ccd.data))\n",
    "        ccd.data -= sky\n",
    "\n",
    "        # Rotate Frame\n",
    "\n",
    "        ccd.data = ccd.data.T\n",
    "        ccd.mask = ccd.mask.T\n",
    "        #ccd.write('obj_'+filename, overwrite=True)\n",
    "        target_list.append(ccd)\n",
    "    \n",
    "    combiner = ccdproc.Combiner(target_list)\n",
    "    red_target = combiner.average_combine()\n",
    "\n",
    "    # red_target = ccdproc.combine(target_list, method='median')\n",
    "\n",
    "    red_target.write('./processed_new/FLUX/{0}.fits'.format(target_list[0].header['object']), overwrite=True)\n",
    "\n",
    "    print(\"Reduced object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(target_list[0].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelength calibration\n",
    "\n",
    "## Reduce arc frames \n",
    "Start by reducing the arc frames. This command can either be run after relevant arcs to the science object have been taken, or all at once towards the end of the night to reduce all arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change observing night if needed. If working on data from the same night as before, skip this cell\n",
    "\n",
    "obs_night = \"20190406\"\n",
    "# workdir = \"/Users/aayushsaxena/Desktop/phd/Reinier_INT/Data/%s/\" %obs_night\n",
    "# os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"./processed_new/ARCS/\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "ic1 = ImageFileCollection(workdir)\n",
    "\n",
    "for filename in ic1.files_filtered(obstype='ARC', object=\"Arc\"):\n",
    "    hdu = fits.open(ic1.location + filename)\n",
    "    ccd = CCDData(hdu[1].data, header=hdu[0].header+hdu[1].header, unit = u.adu)\n",
    "    #this has to be fixed as the bias section does not include the whole section that will be trimmed\n",
    "    ccd = ccdproc.subtract_overscan(ccd, median=True,  overscan_axis=0, fits_section=ccd.header['BIASSEC'])\n",
    "    ccd = ccdproc.trim_image(ccd[:,:4096])\n",
    "    ccd = ccdproc.subtract_bias(ccd, master_bias)\n",
    "    ccd = ccdproc.flat_correct(ccd, master_skyflat)\n",
    "    ccd = ccdproc.cosmicray_lacosmic(ccd, sigclip=4.5, gain=ccd.header['GAIN'], readnoise=ccd.header['READNOIS'])\n",
    "\n",
    "    ccd.data = ccd.data.T\n",
    "    ccd.mask = ccd.mask.T\n",
    "    ccd.write('./processed/ARCS/arc_'+filename, overwrite=True)\n",
    "    \n",
    "print(\"All arcs of the night %s reduced!\" %obs_night)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin wavelength calibration of reduced science frames from the night selected above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select target and the relevant arc - check the log\n",
    "\n",
    "target = \"SP1134+300\"\n",
    "red_arc = fits.getdata('./processed/ARCS/arc_r1458088.fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create 1D arc spectrum\n",
    "# mean_red_arc = np.median(red_arc[:,:], axis=0)\n",
    "mean_red_arc = np.median(red_arc[185:195,:], axis=0)\n",
    "\n",
    "## normalise the arc lines\n",
    "maxval = np.max(mean_red_arc)\n",
    "red_arc_normed = mean_red_arc/maxval\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "plt.plot(red_arc_normed)\n",
    "\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lines for the red arc\n",
    "pixels_red = [1042.33, 1228.61, 1352.1, 1394.7, 1461.7, 1571.4, 1596.94,\n",
    "              1732.9, 1798.7, 1935.0, 2022.74, \n",
    "              2380.47, 2583.5, 2686.1]\n",
    "\n",
    "wavelengths_red = [5852.49, 6143.06, 6334.43, 6402.25, 6506.53, 6678.3, 6717.04,\n",
    "                   6929.47, 7032.41, 7245.17, 7383.98, \n",
    "                   7948.17, 8264.52, 8424.65]\n",
    "\n",
    "\n",
    "# Create x axis\n",
    "xaxis = np.linspace(0,4200, 4200)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(9,5))\n",
    "plt.grid(alpha=0.4)\n",
    "plt.plot(red_arc_normed)\n",
    "\n",
    "line_pix = []\n",
    "\n",
    "for pixel in pixels_red:\n",
    "    # create gaussian to fit to the arc line\n",
    "    p0 = [0.4, pixel, 3.0]\n",
    "    coeffs, covar = optimize.curve_fit(gauss, xaxis[int(pixel-10):int(pixel+10)], red_arc_normed[int(pixel-10):int(pixel+10)], p0=p0, \n",
    "                                       bounds=([0.05, pixel-5, 1.0], [1.0, pixel+5, 6.0]))\n",
    "    line_pix.append(coeffs[1])\n",
    "    plt.plot(np.linspace(pixel-5, pixel+5, 10), gauss(np.linspace(pixel-5, pixel+5, 10), *coeffs))\n",
    "    \n",
    "    \n",
    "sol_red = []\n",
    "for i in range(len(wavelengths_red)):\n",
    "    sol_red.append(wavelengths_red[i]-line_pix[i])\n",
    "\n",
    "plt.grid(alpha=0.4)\n",
    "plt.show()\n",
    "\n",
    "# %matplotlib notebook\n",
    "# plt.plot(line_pix, wavelengths_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try and find a wavelength calibration solution\n",
    "# Fit Red wavelength solutions\n",
    "\n",
    "# initial guess\n",
    "p0 = [1.4, 4440]\n",
    "\n",
    "fit_red, cov_red = optimize.curve_fit(wavesol, line_pix, wavelengths_red, p0=p0)\n",
    "\n",
    "print(fit_red)\n",
    "\n",
    "wavered = wavesol(xaxis, *fit_red)\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "plt.plot(line_pix, wavelengths_red, 'ko')\n",
    "plt.plot(xaxis, wavered)\n",
    "\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate CRPIX and CRDELT values based on new wavelength range and then update the header of the SCI file\n",
    "\n",
    "target = 'SP1708+602'\n",
    "\n",
    "# print(len(wavered))\n",
    "# print(wavered[0], max(wavered))\n",
    "\n",
    "# crval1 = wavered[0]\n",
    "# cdelt1 = (wavered[-1]-wavered[0])/len(wavered)\n",
    "\n",
    "### from known values\n",
    "crval1 = 4215.210956910993\n",
    "cdelt1 = 1.566343826578995\n",
    "cunit1 = 'Angstrom'\n",
    "\n",
    "print(crval1, cdelt1, cunit1)\n",
    "\n",
    "## Update sci file\n",
    "scidata, scihead = fits.getdata(\"./processed_new/FLUX/%s.fits\" %target, header=True)\n",
    "\n",
    "scihead['CRVAL1'] = crval1\n",
    "scihead['CRVAL2'] = 1.0\n",
    "scihead['CDELT1'] = cdelt1\n",
    "scihead['CRPIX2'] = 185.0\n",
    "scihead['CUNIT1'] = cunit1\n",
    "scihead['CUNIT2'] = 'Arcsec'\n",
    "scihead['CTYPE1'] = 'LINEAR'\n",
    "scihead['CTYPE2'] = 'LINEAR'\n",
    "scihead['CD1_1'] = cdelt1\n",
    "scihead['CD2_2'] = 0.44\n",
    "scihead['PV2_1'] = 1.0\n",
    "\n",
    "fits.writeto(\"./processed_new/FLUX/%s_WC.fits\" %target, scidata, header=scihead, overwrite=True)\n",
    "\n",
    "print(\"Wavelength calibration complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of 1D spectrum from 2D\n",
    "\n",
    "Import the WC 2D spectrum and extract a 1D spectrum using an aperture. We will save the output spectrum as an MPDAF Spectrum object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the 2D spectrum\n",
    "\n",
    "# target = \"SP1134+300\"\n",
    "spec2d, spechead = fits.getdata(\"./processed_new/FLUX/%s_WC.fits\" %target, header=True)\n",
    "\n",
    "## Read in the wavelength axis values\n",
    "cdelt = spechead['CDELT1']\n",
    "crval = spechead['CRVAL1']\n",
    "\n",
    "wavelength_1d = WaveCoord(cdelt=cdelt, crval=crval, cunit=u.Angstrom)\n",
    "\n",
    "### Select the central pixel and the aperture size. Note that the extracted aperture will be over 2x the aperture size specified here\n",
    "central_pix = 185\n",
    "aperture = 5\n",
    "\n",
    "spectrum_1d = np.sum(spec2d[central_pix-aperture:central_pix+aperture,:], axis=0)\n",
    "# print(np.shape(spectrum_1d))\n",
    "\n",
    "spectrum_mpdaf = Spectrum(wave=wavelength_1d, data=spectrum_1d, data_header=spechead)\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "spectrum_mpdaf.rebin(1).plot(color='k')\n",
    "plt.xlim(5600, 9600)\n",
    "# plt.ylim(-20,100)\n",
    "\n",
    "### Show lines\n",
    "# z = 6.246\n",
    "# plt.axvline(1216.0*(1+z), color='k', ls='--', alpha=0.5)\n",
    "# plt.axvline(1037.6*(1+z), color='k', ls='--', alpha=0.5)\n",
    "# plt.axvline(949.74*(1+z), color='k', ls='--', alpha=0.5)\n",
    "# plt.axvline(1240.*(1+z), color='k', ls='--', alpha=0.5)\n",
    "# plt.axvline(1302.*(1+z), color='k', ls='--', alpha=0.5)\n",
    "# #plt.axvline(7452.538*(1+z), color='k', ls='--', alpha=0.5)\n",
    "\n",
    "# plt.savefig(\"./processed_new/FLUX/%s_1D.png\" %target, overwrite=True)\n",
    "plt.show()\n",
    "\n",
    "spectrum_mpdaf.write(\"./processed_new/FLUX/%s_1D.fits\" %target)\n",
    "\n",
    "print(\"1D spectrum extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flux calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "objects = [\"SP1708+602\"] # Enter flux calibrator object name(s) (see from observing log)\n",
    "#######################\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"./processed_new/FLUX/\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "### Ignore masked array warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "### Refresh the file list to include new exposures\n",
    "ic1 = ImageFileCollection(workdir)\n",
    "    \n",
    "### Reduce science frame\n",
    "for objname in objects:\n",
    "    print(\"Reducing:\", objname)\n",
    "    target_list = []\n",
    "    for ifx, filename in enumerate(ic1.files_filtered(obstype='TARGET', object=objname)):\n",
    "        print('{0} {1}'.format(ifx+1, filename))\n",
    "        hdu = fits.open(ic1.location + filename)\n",
    "        ccd = CCDData(hdu[1].data, header=hdu[0].header+hdu[1].header, unit = u.adu)\n",
    "        #this has to be fixed as the bias section does not include the whole section that will be trimmed\n",
    "\n",
    "        ccd = ccdproc.cosmicray_lacosmic(ccd, sigclip=4., niter=10, sigfrac=0.3, psffwhm=2.5, \n",
    "                                         gain=ccd.header['GAIN'], readnoise=ccd.header['READNOIS'])\n",
    "        ccd = ccdproc.subtract_overscan(ccd, median=True,  overscan_axis=0, fits_section=ccd.header['BIASSEC'])\n",
    "        ccd = ccdproc.trim_image(ccd, fits_section=ccd.header['TRIMSEC'] )\n",
    "        ccd = ccdproc.subtract_bias(ccd, master_bias)\n",
    "        ccd = ccdproc.flat_correct(ccd, master_skyflat)\n",
    "\n",
    "\n",
    "        # Do sky subtraction\n",
    "        # ccd.mask[:,690:700] = True\n",
    "        sky = fit_background(np.ma.array(ccd.data, mask=ccd.mask))\n",
    "        ccd.data -= sky\n",
    "\n",
    "        # Rotate Frame\n",
    "\n",
    "        ccd.data = ccd.data.T\n",
    "        ccd.mask = ccd.mask.T\n",
    "        #ccd.write('obj_'+filename, overwrite=True)\n",
    "        target_list.append(ccd)\n",
    "\n",
    "    red_target = ccdproc.combine(target_list, method='median')\n",
    "\n",
    "    red_target.write('./processed_new/FLUX/{0}.fits'.format(target_list[0].header['object']), overwrite=True)\n",
    "\n",
    "    print(\"Reduced object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the standard star spectrum\n",
    "\n",
    "fluxdata = np.loadtxt(\"./processed/FLUX/SP1708+602.txt\")\n",
    "\n",
    "wave = np.zeros(len(fluxdata))\n",
    "flux_AB = np.zeros(len(fluxdata))\n",
    "flux = np.zeros(len(fluxdata))\n",
    "\n",
    "for i in range(len(fluxdata)):\n",
    "    wave[i] = fluxdata[i][0]\n",
    "    flux_AB[i] = fluxdata[i][1]\n",
    "    flux_Jy = 10**(-(flux_AB[i] - 8.9)/2.5) # Flux in Jy\n",
    "    flux_nu = flux_Jy * 1e-23\n",
    "    flux[i] = flux_nu * (3e18)/(wave[i]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit polynomial to the spectrum to visualise the fitting.\n",
    "## Play around with the type of polynomial and/or degree until satisfied with the fit \n",
    "cont = np.polyfit(wave, flux_AB, 2)\n",
    "\n",
    "xaxis = np.linspace(3000, 9000, 1000)\n",
    "fluxpol = np.polyval(cont, xaxis)\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.plot(wave, flux_AB)\n",
    "plt.plot(xaxis, fluxpol)\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Look at atmopheric extinction curve\n",
    "data = np.loadtxt(\"/Users/aayushsaxena/Desktop/phd/HzQ_2019/Data/extinction.dat.txt\")\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "w_corr = np.zeros(len(data))\n",
    "fcorr_AB = np.zeros(len(data))\n",
    "f_corr = np.zeros(len(data))\n",
    "\n",
    "### convert the extinction magnitude into flux density\n",
    "### Add the flux density to the final calibrated flux, taking also into account the airmass\n",
    "\n",
    "# for i in range(len(data)):\n",
    "#     wl.append(data[i][0])\n",
    "#     ext.append(data[i][1])\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    w_corr[i] = (data[i][0])\n",
    "    fcorr_AB[i] = data[i][1]\n",
    "#     flux_Jy = 10**(-(f_AB[i] - 8.9)/2.5) # Flux in Jy\n",
    "#     flux_nu = flux_Jy * 1e-23\n",
    "#     f_corr[i] = flux_nu * (3e18)/(w_corr[i]**2)\n",
    "    \n",
    "%matplotlib notebook\n",
    "plt.plot(w_corr, fcorr_AB)\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "# plt.xlim(5000, 9600)\n",
    "# plt.ylim(0.0, 0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit polynomial to the spectrum to visualise the fitting.\n",
    "## Play around with the type of polynomial and/or degree until satisfied with the fit \n",
    "extinction = np.polyfit(w_corr, np.log10(fcorr_AB), 5)\n",
    "\n",
    "xcorr= np.linspace(3000, 11000, 1000)\n",
    "extpol = np.polyval(extinction, xcorr)\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.plot(w_corr,fcorr_AB)\n",
    "plt.plot(xcorr, 10**(extpol))\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's fold in the atmospheric extinction correction to obtain the \"observed\" spectrum\n",
    "### which will then be compared with the extracted 1D\n",
    "\n",
    "### m(λ)=m0(λ)+κ(λ)X(z)\n",
    "\n",
    "x_obs = np.linspace(4000, 10000)\n",
    "obs_AB = np.zeros(len(x_obs))\n",
    "\n",
    "########\n",
    "airmass = 1.15\n",
    "########\n",
    "\n",
    "### Evaluate polynomials on the new xaxis\n",
    "stdflux = np.polyval(cont, x_obs)\n",
    "corrflux = np.polyval(extinction, x_obs)\n",
    "\n",
    "for i in range(len(x_obs)):\n",
    "    obs_AB[i] = (stdflux[i]) + (10**(corrflux[i]) * airmass)\n",
    "\n",
    "### Display the extinction corrected flux standard\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "# plt.plot(wave,flux_AB)\n",
    "plt.plot(x_obs, obs_AB)\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now convert the ext corrected flux of standard star to erg/s\n",
    "\n",
    "flux = np.zeros(len(x_obs))\n",
    "\n",
    "for i in range(len(flux)):\n",
    "    flux_Jy = 10**(-(obs_AB[i] - 8.9)/2.5) # Flux in Jy\n",
    "    flux_nu = flux_Jy * 1e-23\n",
    "    flux[i] = flux_nu * (3e18)/(7505**2)\n",
    "    \n",
    "### Fit a function to this new spectrum\n",
    "\n",
    "flux_polfit = np.polyfit(x_obs, np.log10(flux), 11)\n",
    "fluxstd_pol = np.polyval(flux_polfit, x_obs)\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.plot(x_obs, flux)\n",
    "plt.plot(x_obs, 10**(fluxstd_pol))\n",
    "\n",
    "# plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's convert this into a mpdaf spectrum\n",
    "\n",
    "## Create a fake wavelength axis, using the crval and crdelt values from the flux standard WHT spectrum\n",
    "## Using the fitted Chebyshev functions, calculate the flux and then create and mpdaf spectrum.\n",
    "## Then create subspectra in the wavelength range probed and calculate a response function.\n",
    "## This response function must then be applied to the extracted 1D spectra, accounting for exposure times\n",
    "\n",
    "## import the actual observation of the flux standard to use as template for the mpdaf spectrum\n",
    "fluxspec, fluxhead = fits.getdata(\"./processed_new/FLUX/SP1708+602_1D.fits\",\n",
    "                                  header=True)\n",
    "\n",
    "crval = fluxhead['CRVAL1']\n",
    "cdelt = fluxhead['CDELT1']\n",
    "\n",
    "xaxis = np.zeros(len(fluxspec))\n",
    "\n",
    "xaxis[0] = crval\n",
    "\n",
    "for i in range(1, len(xaxis)):\n",
    "    xaxis[i] = xaxis[i-1] + cdelt\n",
    "    \n",
    "print(xaxis) # fake x axis defined\n",
    "                                  \n",
    "## Assign fake flux using the fitted polynomials\n",
    "fluxstd = np.zeros(len(xaxis))\n",
    "fluxstd = 10**(np.polyval(flux_polfit, xaxis))\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "plt.plot(xaxis, fluxstd)\n",
    "plt.xlim(5500, 9500)\n",
    "plt.yscale('log')\n",
    "# plt.ylim(1e-16, 1e-13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the mpdaf spectrum\n",
    "fluxwave = WaveCoord(cdelt = cdelt, crval = crval, cunit = u.Angstrom)\n",
    "fluxspec = Spectrum(wave=fluxwave, data=fluxstd)\n",
    "\n",
    "## Show the mpdaf spectrum\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "fluxspec.plot()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RED ARM\n",
    "## Load in the 1D extracted spectrum of the flux standard\n",
    "\n",
    "spec1d = Spectrum(\"./processed_new/FLUX/SP1708+602_1D.fits\")\n",
    "flux_exp = 600.\n",
    "\n",
    "### Let's extract a subspectrum from the original flux standard spectrum to match the targets\n",
    "### First rebin with the same wavelength delta\n",
    "\n",
    "print(len(fluxspec.data))\n",
    "print(len(spec1d.data))\n",
    "\n",
    "### Mask bad regions\n",
    "spec1d.mask_region(lmin=7563, lmax=7720, unit=u.angstrom)\n",
    "spec1d.mask_region(lmin=6514, lmax=6613, unit=u.angstrom)\n",
    "spec1d.mask_region(lmin=6836, lmax=6968, unit=u.angstrom)\n",
    "# spec1d.mask_region(lmin=7720, lmax=7977, unit=u.angstrom)\n",
    "spec1d.mask_region(lmin=8112, lmax=8270, unit=u.angstrom)\n",
    "# # spec1d.mask_region(lmin=8498, lmax=8820, unit=u.angstrom)\n",
    "spec1d.mask_region(lmin=8580, lmax=8710, unit=u.angstrom)\n",
    "\n",
    "# spec1d.mask_region(lmin=8921, lmax=9041, unit=u.angstrom)\n",
    "\n",
    "\n",
    "spec1d.interp_mask()\n",
    "\n",
    "# fluxspec = fluxstd_spec.resample(1.719097201253421, unit=u.Angstrom)\n",
    "# fluxspec_sub = fluxstd_spec.subspec(lmin=5000, lmax=9400, unit=u.Angstrom)\n",
    "# spec1d_sub = spec1d.subspec(lmin=5000, lmax=9400, unit=u.Angstrom)\n",
    "\n",
    "response_red = (spec1d.data/flux_exp) / fluxspec.data # (counts/s) / flux\n",
    "\n",
    "responsespec = Spectrum(wave=spec1d.wave, data=response_red)\n",
    "# responsespec = Spectrum(\"./processed/FLUX/response.fits\")\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "responsespec.rebin(5).plot()\n",
    "plt.ylim(1e14, 1e16)\n",
    "plt.xlim(5500, 9600)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "\n",
    "## Save the response spectrum\n",
    "# responsespec.rebin(5).write(\"./processed/FLUX/response.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Response calculated. Now let us import target data, make a subspec between the wavelength and calibrate\n",
    "\n",
    "obj_name = \"P144+50\"\n",
    "\n",
    "scispec = Spectrum(\"./processed_new/SCI/%s_1D_new.fits\" %obj_name)\n",
    "sci_exptime = 7200.\n",
    "\n",
    "# Apply the response curve\n",
    "scispec_fc = (scispec.data/sci_exptime) / responsespec.data\n",
    "\n",
    "\n",
    "### Calculate noise from the 2D image too\n",
    "night_new, night_head = fits.getdata(\"/Users/aayushsaxena/Desktop/phd/HzQ_2019/P144+50/P144+50_WC_new.fits\",\n",
    "                                    header=True)\n",
    "\n",
    "## Read in the wavelength axis values\n",
    "cdelt = night_head['CDELT1']\n",
    "crval = night_head['CRVAL1']\n",
    "\n",
    "### Define wavelength axis for noise sepctrum\n",
    "wavelength = WaveCoord(cdelt=cdelt, crval=crval, cunit=u.Angstrom)\n",
    "\n",
    "central_pix1 = 210\n",
    "aperture1 = 5\n",
    "noise1 = np.sum(night_new[central_pix1-aperture1:central_pix1+aperture1,:], axis=0)\n",
    "\n",
    "central_pix2 = 165\n",
    "aperture2 = 5\n",
    "noise2 = np.sum(night_new[central_pix2-aperture2:central_pix2+aperture2,:], axis=0)\n",
    "\n",
    "noise = np.mean([noise1, noise2], axis=0)\n",
    "\n",
    "noise_spec = Spectrum(wave=wavelength, data=noise)\n",
    "\n",
    "### Flux calibrate the noise\n",
    "### add sky plus poissonian noise\n",
    "noise_fc = (np.sqrt(scispec.data)/sci_exptime) / responsespec.data\n",
    "\n",
    "\n",
    "# Create new spectrum object using the flux calibrated values and add error\n",
    "scispec_1d = Spectrum(wave=scispec.wave, data=scispec_fc, var=noise_fc, unit=u.erg/(u.s * u.cm**2 * u.Angstrom))\n",
    "\n",
    "noisespec_1d = Spectrum(wave=scispec.wave, data=noise_fc, unit=u.erg/(u.s * u.cm**2 * u.Angstrom))\n",
    "\n",
    "print(\"Flux calibrated spectrum produced!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show FC spectrum\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "scispec_1d.rebin(2).plot(c='k', linewidth=0.8)\n",
    "noisespec_1d.rebin(2).plot(c='orange', alpha=0.5)\n",
    "\n",
    "plt.ylim(-0.2e-17,2.5e-17)\n",
    "plt.xlim(5300, 9600)\n",
    "\n",
    "plt.xlabel(r\"Wavelength ($\\AA$)\", fontsize=14)\n",
    "plt.ylabel(r\"Flux (erg/s/cm$^2$/$\\AA$)\", fontsize=14)\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "plt.savefig(\"./processed_new/SCI/%s_1D_FC.png\" %obj_name, dpi=200, bbox_inches=\"tight\", overwrite=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Save the flux calibrated spectrum\n",
    "# scispec_1d.write(\"./processed/SCI/%s_1D_FC.fits\" %obj_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the flux calibrated subspectrum in the wavelength ranges that are covered\n",
    "specfc_sub = scispec_1d.subspec(lmin=5300, lmax=9600, unit=u.angstrom)\n",
    "\n",
    "specfc_sub.write(\"./processed_new/SCI/P144+50_1D_FC.fits\")\n",
    "# %matplotlib notebook\n",
    "# specfc_sub.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack 1D observations\n",
    "\n",
    "Take the extracted 1D spectra and do a summed stack in a bid to enhance signal to noise. Important to take note of the total exposure time when flux calibrating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the spectra\n",
    "\n",
    "specdir = \"/Users/aayushsaxena/Desktop/phd/HzQ_2019/Data/INT_2019B/\"\n",
    "\n",
    "os.chdir(specdir)\n",
    "\n",
    "spec1 = Spectrum(\"./20190526/processed/SCI/P144+50_1D.fits\")\n",
    "spec2 = Spectrum(\"./20190523/processed/SCI/P144+50_1D.fits\")\n",
    "spec3 = Spectrum(\"../20190406/trimmed/processed/SCI/P144+50_1D.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the two spectra\n",
    "\n",
    "stack_data = spec1.data+spec2.data+spec3.data\n",
    "stack_spec = Spectrum(wave=spec1.wave, data=stack_data)\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize=(10,3), dpi=100)\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "(stack_spec/227.5).rebin(2).plot(color='k')\n",
    "\n",
    "plt.xlim(6000, 9500)\n",
    "plt.ylim(-0.2,1.2)\n",
    "\n",
    "plt.xlabel(r\"Wavelength ($\\AA$)\", fontsize=12)\n",
    "plt.ylabel(\"Flux (arbitrary units)\", fontsize=12)\n",
    "\n",
    "### Show lines\n",
    "lines = [1025.7, 1034.8, 1215.7, 1240.8, 1262.6]\n",
    "line_names = [r\"Ly$\\beta$\", \"O VI\", r\"Ly$\\alpha$\", \"N V\", \"Si II\"]\n",
    "redshift = 5.66\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    line_x = lines[i]*(1+redshift)\n",
    "    plt.axvline(x=line_x, ls='--', c='k', alpha=0.5)\n",
    "    plt.text(line_x+7, 1.0, line_names[i], fontsize=8, rotation=90)\n",
    "    \n",
    "# stack_spec.write(\"/Users/aayushsaxena/Desktop/phd/HzQ_2019/P144+50_stacked_1D.fits\")\n",
    "    \n",
    "# plt.savefig(\"/Users/aayushsaxena/Desktop/phd/HzQ_2019/P144+50_stacked_1D.png\", bbox_inches=\"tight\", overwrite=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(extpol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JWST Python3.11",
   "language": "python",
   "name": "jwst-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
